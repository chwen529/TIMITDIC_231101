{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "greatest-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "from tensorflow_core.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow_core.python.keras.utils import np_utils\n",
    "from tensorflow_core.python.keras.models import Sequential\n",
    "from tensorflow_core.python.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.python import math_ops\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow_core.python.keras.layers import Activation\n",
    "from tensorflow_core.python.keras.utils import get_custom_objects   # 自定義gelu\n",
    "\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "725d16cb",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sentence_type = 'SA1'\n",
    "# sentence_type = 'SA2'\n",
    "# sentence_type = 'SA'\n",
    "# sentence_type = 'SX'\n",
    "\n",
    "Tr_ver = 'orig_50_DR25_M_'\n",
    "Te_ver = 'orig_50_DR25_M_'\n",
    "# --------------------------------------------------\n",
    "Tr_ver = 'pe_50_DR25_M_'\n",
    "Te_ver = 'pe_50_DR25_M_'\n",
    "# --------------------------------------------------\n",
    "Tr_ver = 'pe_20_DR25_M_'\n",
    "Te_ver = 'pe_20_DR25_M_'\n",
    "\n",
    "Tr_ver += sentence_type + '_'\n",
    "Te_ver += sentence_type + '_'\n",
    "\n",
    "# Tr_ver += '2_'\n",
    "# Te_ver += '2_'\n",
    "\n",
    "shape = 50\n",
    "\n",
    "now_path = r'D:\\TIMITDIC_231101'\n",
    "data_path = now_path + '_data_all_sentence'\n",
    "\n",
    "Tr_CDF_path = os.path.join(data_path, 'TRAIN', 'cnn_dataset_librosa')\n",
    "Te_CDF_path = os.path.join(data_path, 'TEST', 'cnn_dataset_librosa')\n",
    "\n",
    "Tr_DS_path = os.path.join(Tr_CDF_path, 'mfcc', Tr_ver + 'SoundDataset.npz')\n",
    "\n",
    "Te_DS_path = os.path.join(Te_CDF_path, 'mfcc', Te_ver + 'SoundDataset.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "funky-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tr_DS = np.load(Tr_DS_path)\n",
    "Te_DS = np.load(Te_DS_path)\n",
    "\n",
    "train_value, train_label = Tr_DS['TrainValue'], Tr_DS['TrainLabel_class']\n",
    "test_value, test_label = Te_DS['TestValue'], Te_DS['TestLabel_class']\n",
    "# test_value, test_label, test_label2 = Te_DS['TestValue'], Te_DS['TestLabel_class'], Te_DS['TestLabel_type']\n",
    "\n",
    "train_value_4D = train_value.reshape(train_value.shape[0], shape, shape, 1).astype('float32')\n",
    "test_value_4D = test_value.reshape(test_value.shape[0], shape, shape, 1).astype('float32')\n",
    "\n",
    "# 向量轉換為二進制(只有0和1)的矩陣類型\n",
    "# 但train_label、test_label原先資料就都是0跟1?\n",
    "train_label_OneHot = np_utils.to_categorical(train_label)\n",
    "test_label_OneHot = np_utils.to_categorical(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "2a23f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Davis( Activation ):    \n",
    "    def __init__(self, activation, **kwargs):\n",
    "        super(Davis, self).__init__(activation, **kwargs)\n",
    "        self.__name__ = 'custom_gelu'\n",
    "\n",
    "def custom_gelu(x):\n",
    "    return 0.5 * x * (1 + math_ops.tanh(math_ops.sqrt(2 / np.pi) * (x + 0.044715 * math_ops.pow(x, 3))))\n",
    "\n",
    "get_custom_objects().update({'custom_gelu': Davis(custom_gelu)})\n",
    "get_custom_objects().update({'Davis': (Activation)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "sonic-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_cate = 'relu'\n",
    "activation_cate = 'custom_gelu'\n",
    "# activation_cate = 'sigmoid'\n",
    "# activation_cate = 'elu'\n",
    "# activation_cate = 'tanh'\n",
    "kernel_size = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (kernel_size, kernel_size), input_shape=(shape, shape, 1), padding='same', activation=activation_cate))\n",
    "model.add(Conv2D(64, (kernel_size, kernel_size), padding='same', activation=activation_cate))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(64, (kernel_size, kernel_size), padding='same', activation=activation_cate))\n",
    "model.add(Conv2D(128, (kernel_size, kernel_size), padding='same', activation=activation_cate))\n",
    "# model.add(Conv2D(128, (3, 3), padding='same', activation='custom_gelu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "# model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "# model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Conv2D(1024, (3, 3), padding='same', activation='relu'))\n",
    "# model.add(Conv2D(1024, (3, 3), padding='same', activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(1024, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(256, activation='custom_gelu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(64, activation=activation_cate))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation=activation_cate))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation=activation_cate))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "adjustable-fitness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_188 (Conv2D)          (None, 50, 50, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_189 (Conv2D)          (None, 50, 50, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_94 (MaxPooling (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_189 (Dropout)        (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_190 (Conv2D)          (None, 25, 25, 64)        102464    \n",
      "_________________________________________________________________\n",
      "conv2d_191 (Conv2D)          (None, 25, 25, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_95 (MaxPooling (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_190 (Dropout)        (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_47 (Flatten)         (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 128)               2359424   \n",
      "_________________________________________________________________\n",
      "dropout_191 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_192 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 2,775,138\n",
      "Trainable params: 2,775,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss='mean_squared_error',  # mean_squared_error, binary_crossentropy, categorical_crossentropy\n",
    "              optimizer=\"adam\",  # sgd, rmsprop, adam\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "conceptual-participant",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 392 samples, validate on 98 samples\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[300,128,25,25] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_94/Adam/gradients/gradients/max_pooling2d_95/MaxPool_grad/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_12764\\388273600.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m                         \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m300\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m                         \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m300\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m                         \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m                         \u001B[1;31m# callbacks=[early_stopping])\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m                         )\n",
      "\u001B[1;32m~\\anaconda3\\envs\\TF-1-15-GPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m         \u001B[0mmax_queue_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmax_queue_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    726\u001B[0m         \u001B[0mworkers\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 727\u001B[1;33m         use_multiprocessing=use_multiprocessing)\n\u001B[0m\u001B[0;32m    728\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    729\u001B[0m   def evaluate(self,\n",
      "\u001B[1;32m~\\anaconda3\\envs\\TF-1-15-GPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001B[0m\n\u001B[0;32m    673\u001B[0m         \u001B[0mvalidation_steps\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mvalidation_steps\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    674\u001B[0m         \u001B[0mvalidation_freq\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mvalidation_freq\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 675\u001B[1;33m         steps_name='steps_per_epoch')\n\u001B[0m\u001B[0;32m    676\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    677\u001B[0m   def evaluate(self,\n",
      "\u001B[1;32m~\\anaconda3\\envs\\TF-1-15-GPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001B[0m in \u001B[0;36mmodel_iteration\u001B[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001B[0m\n\u001B[0;32m    392\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    393\u001B[0m         \u001B[1;31m# Get outputs.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 394\u001B[1;33m         \u001B[0mbatch_outs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mins_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    395\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_outs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    396\u001B[0m           \u001B[0mbatch_outs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mbatch_outs\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\TF-1-15-GPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m   3474\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3475\u001B[0m     fetched = self._callable_fn(*array_vals,\n\u001B[1;32m-> 3476\u001B[1;33m                                 run_metadata=self.run_metadata)\n\u001B[0m\u001B[0;32m   3477\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call_fetch_callbacks\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfetched\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_fetches\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3478\u001B[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001B[1;32m~\\anaconda3\\envs\\TF-1-15-GPU\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1470\u001B[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001B[0;32m   1471\u001B[0m                                                \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1472\u001B[1;33m                                                run_metadata_ptr)\n\u001B[0m\u001B[0;32m   1473\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mrun_metadata\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1474\u001B[0m           \u001B[0mproto_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_session\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTF_GetBuffer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrun_metadata_ptr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: OOM when allocating tensor with shape[300,128,25,25] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_94/Adam/gradients/gradients/max_pooling2d_95/MaxPool_grad/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "# 創建一個早停法的回調函數\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=100, restore_best_weights=True)\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=100, restore_best_weights=True)\n",
    "\n",
    "train_history=model.fit(x=train_value_4D,\n",
    "                        y=train_label_OneHot,\n",
    "                        validation_split=0.2,\n",
    "                        epochs=300,\n",
    "                        batch_size=300,\n",
    "                        verbose=2,\n",
    "                        # callbacks=[early_stopping])\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "now_str = datetime.datetime.now()\n",
    "now_str = datetime.datetime.strftime(now_str, '%Y%m%d_%H%M%S')\n",
    "\n",
    "def show_train_history(train_history, train, validation):\n",
    "    # 定義show_train_history函數，輸入下列參數:之前訓練過程所產生的train_history、\n",
    "    # ...訓練資料的執行結果、驗證資料的執行結果\n",
    "    print(train_history.history)\n",
    "    plt.style.use('default')\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train_History')  # 顯示圖的標題\n",
    "    plt.ylabel(train)  # 顯示y軸的標籤\n",
    "    plt.xlabel('Epoch')  # 設定x軸標籤是'Epoch'\n",
    "    plt.legend(['train', 'validation'], loc='best')\n",
    "    # 設定國例是顯示'train', 'validation',位置在左上角\n",
    "\n",
    "    train_history_path = os.path.join(now_path, 'train_history', Tr_ver)\n",
    "    os.makedirs(train_history_path, exist_ok=True)\n",
    "\n",
    "    plt.savefig(os.path.join(train_history_path, now_str + '_' + train + '.png'), bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "show_train_history(train_history, 'loss', 'val_loss')\n",
    "show_train_history(train_history, 'acc', 'val_acc')\n",
    "# show_train_history(train_history, 'accuracy', 'val_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-spare",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_value_4D, test_label_OneHot)\n",
    "print('loss=', scores[0], '\\nacc=', scores[1])\n",
    "\n",
    "f = open(os.path.join(now_path, 'train_history', 'train_history.txt'), 'a+')  # a+\n",
    "\n",
    "content = f.read()\n",
    "f.seek(0, 0)\n",
    "\n",
    "f.write('\\n' + '---------------------------------' + '\\n')\n",
    "f.write('\\n' + '*****' + Tr_ver + '*****' + '\\n')\n",
    "f.write(now_str + '\\n')\n",
    "f.write('loss=' + '\\n' + str(scores[0]) + '\\n')\n",
    "f.write('acc=' + '\\n' + str(scores[1]))\n",
    "\n",
    "f.write('\\n' + content)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用pd.crosstab建立混淆矩陣，輸入下列參數:\n",
    "prediction = model.predict_classes(test_value_4D)\n",
    "pd.crosstab(test_label,  # 測試資料數字影像的其實值\n",
    "            prediction,  # 測試資料數字影像的預測結果\n",
    "            rownames=['label'],  # 設定行的名稱是label\n",
    "            colnames=['predict'])  # 設定列的名稱是predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-jonathan",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MWpath = os.path.join(now_path, '..\\..', 'model_weight')\n",
    "os.makedirs(MWpath, exist_ok=True)\n",
    "Wver = now_path.split('\\\\')[-1]\n",
    "model.save(os.path.join(MWpath, Tr_ver + 'SoundWeight_' + Wver + '_type2.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF-1-15-GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}